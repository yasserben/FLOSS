{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\ude80 FLOSS: Free Lunch in Open-vocabulary Semantic Segmentation\n",
        "\n",
        "## Reproducibility Notebook\n",
        "\n",
        "This notebook allows you to reproduce the template ranking results from the FLOSS paper.\n",
        "\n",
        "**Paper:** [FLOSS: Free Lunch in Open-vocabulary Semantic Segmentation](https://arxiv.org/abs/2504.10487)  \n",
        "**Project Page:** [https://yasserben.github.io/FLOSS/](https://yasserben.github.io/FLOSS/)  \n",
        "**GitHub:** [https://github.com/yasserben/FLOSS](https://github.com/yasserben/FLOSS)\n",
        "\n",
        "---\n",
        "\n",
        "### \ud83d\udccb What This Notebook Does\n",
        "\n",
        "1. **Load pre-computed features** from HuggingFace (or compute them on-the-fly)\n",
        "2. **Compute template rankings** using entropy (our method) or your custom metric\n",
        "3. **Reproduce the paper's results** or experiment with new ranking approaches\n",
        "4. **Visualize** the rankings and compare different metrics\n",
        "\n",
        "### \ud83d\udca1 Key Insight from FLOSS\n",
        "\n",
        "> For each class, there exist single-template classifiers that significantly outperform the conventional averaged classifier using all 80 templates.\n",
        "\n",
        "We use **entropy** as an unsupervised metric to identify the best template for each class, without requiring any ground-truth labels!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udce6 Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Dependencies (Run this first!)\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"\ud83d\udd27 Installing dependencies for Google Colab...\")\n",
        "    !pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
        "    !pip install -q open-clip-torch==2.24.0\n",
        "    !pip install -q einops ftfy regex tqdm omegaconf\n",
        "    !pip install -q huggingface_hub datasets\n",
        "    !pip install -q matplotlib seaborn pandas\n",
        "    \n",
        "    import os\n",
        "    if not os.path.exists('/content/FLOSS'):\n",
        "        !git clone https://github.com/yasserben/FLOSS.git /content/FLOSS\n",
        "    \n",
        "    sys.path.insert(0, '/content/FLOSS')\n",
        "    %cd /content/FLOSS\n",
        "    print(\"\u2705 Colab setup complete!\")\n",
        "else:\n",
        "    print(\"\ud83d\udccd Running locally.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Optional\n",
        "from collections import defaultdict\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"\ud83d\udda5\ufe0f Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfa8 Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "DATASET = \"cityscapes\"  # Options: cityscapes, pascalvoc20, pascalco59, ade20k, cocostuff\n",
        "MODEL_TYPE = \"maskclip\"  # Options: maskclip, naclip, clipdinoiser\n",
        "USE_PRECOMPUTED = True  # If True, downloads from HuggingFace\n",
        "HF_REPO = \"yasserben/floss-features\"\n",
        "\n",
        "print(f\"\ud83d\udcca Configuration:\")\n",
        "print(f\"   Dataset: {DATASET}\")\n",
        "print(f\"   Model: {MODEL_TYPE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ImageNet Templates (80 prompts)\n",
        "IMAGENET_TEMPLATES = [\n",
        "    'a bad photo of a {}.', 'a photo of many {}.', 'a sculpture of a {}.',\n",
        "    'a photo of the hard to see {}.', 'a low resolution photo of the {}.',\n",
        "    'a rendering of a {}.', 'graffiti of a {}.', 'a bad photo of the {}.',\n",
        "    'a cropped photo of the {}.', 'a tattoo of a {}.', 'the embroidered {}.',\n",
        "    'a photo of a hard to see {}.', 'a bright photo of a {}.', 'a photo of a clean {}.',\n",
        "    'a photo of a dirty {}.', 'a dark photo of the {}.', 'a drawing of a {}.',\n",
        "    'a photo of my {}.', 'the plastic {}.', 'a photo of the cool {}.',\n",
        "    'a close-up photo of a {}.', 'a black and white photo of the {}.',\n",
        "    'a painting of the {}.', 'a painting of a {}.', 'a pixelated photo of the {}.',\n",
        "    'a sculpture of the {}.', 'a bright photo of the {}.', 'a cropped photo of a {}.',\n",
        "    'a plastic {}.', 'a photo of the dirty {}.', 'a jpeg corrupted photo of a {}.',\n",
        "    'a blurry photo of the {}.', 'a photo of the {}.', 'a good photo of the {}.',\n",
        "    'a rendering of the {}.', 'a {} in a video game.', 'a photo of one {}.',\n",
        "    'a doodle of a {}.', 'a close-up photo of the {}.', 'a photo of a {}.',\n",
        "    'the origami {}.', 'the {} in a video game.', 'a sketch of a {}.',\n",
        "    'a doodle of the {}.', 'a origami {}.', 'a low resolution photo of a {}.',\n",
        "    'the toy {}.', 'a rendition of the {}.', 'a photo of the clean {}.',\n",
        "    'a photo of a large {}.', 'a rendition of a {}.', 'a photo of a nice {}.',\n",
        "    'a photo of a weird {}.', 'a blurry photo of a {}.', 'a cartoon {}.',\n",
        "    'art of a {}.', 'a sketch of the {}.', 'a embroidered {}.',\n",
        "    'a pixelated photo of a {}.', 'itap of the {}.', 'a jpeg corrupted photo of the {}.',\n",
        "    'a good photo of a {}.', 'a plushie {}.', 'a photo of the nice {}.',\n",
        "    'a photo of the small {}.', 'a photo of the weird {}.', 'the cartoon {}.',\n",
        "    'art of the {}.', 'a drawing of the {}.', 'a photo of the large {}.',\n",
        "    'a black and white photo of a {}.', 'the plushie {}.', 'a dark photo of a {}.',\n",
        "    'itap of a {}.', 'graffiti of the {}.', 'a toy {}.', 'itap of my {}.',\n",
        "    'a photo of a cool {}.', 'a photo of a small {}.', 'a tattoo of the {}.',\n",
        "]\n",
        "\n",
        "print(f\"\ud83d\udcdd Loaded {len(IMAGENET_TEMPLATES)} templates\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset Class Names\n",
        "CLASS_NAMES = {\n",
        "    \"cityscapes\": [\n",
        "        \"road\", \"sidewalk\", \"building\", \"wall\", \"fence\", \"pole\",\n",
        "        \"traffic light\", \"traffic sign\", \"vegetation\", \"terrain\", \"sky\",\n",
        "        \"person\", \"rider\", \"car\", \"truck\", \"bus\", \"train\", \"motorcycle\", \"bicycle\"\n",
        "    ],\n",
        "    \"pascalvoc20\": [\n",
        "        \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\",\n",
        "        \"chair\", \"cow\", \"dining table\", \"dog\", \"horse\", \"motorbike\", \"person\",\n",
        "        \"potted plant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"\n",
        "    ],\n",
        "}\n",
        "\n",
        "current_classes = CLASS_NAMES.get(DATASET, CLASS_NAMES[\"cityscapes\"])\n",
        "NUM_CLASSES = len(current_classes)\n",
        "print(f\"\ud83c\udff7\ufe0f {DATASET}: {NUM_CLASSES} classes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83e\udde0 Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CLIP Text Encoder\n",
        "class CLIPTextEncoder:\n",
        "    def __init__(self, model_name=\"ViT-B-16\", pretrained=\"laion2b_s34b_b88k\", device=DEVICE):\n",
        "        from open_clip import create_model_from_pretrained, get_tokenizer\n",
        "        self.device = device\n",
        "        print(f\"\ud83d\udce5 Loading CLIP text encoder...\")\n",
        "        self.model, _ = create_model_from_pretrained(model_name, pretrained=pretrained)\n",
        "        self.model.eval().to(device)\n",
        "        self.tokenizer = get_tokenizer(model_name)\n",
        "        print(\"\u2705 Text encoder loaded!\")\n",
        "        \n",
        "    @torch.no_grad()\n",
        "    def encode_text(self, texts):\n",
        "        tokens = self.tokenizer(texts).to(self.device)\n",
        "        features = self.model.encode_text(tokens)\n",
        "        features = features / features.norm(dim=-1, keepdim=True)\n",
        "        return features\n",
        "    \n",
        "    @torch.no_grad()\n",
        "    def compute_all_text_features(self, class_names, templates=IMAGENET_TEMPLATES):\n",
        "        per_template_features = []\n",
        "        for template in tqdm(templates, desc=\"Computing text features\"):\n",
        "            prompts = [template.format(cls) for cls in class_names]\n",
        "            features = self.encode_text(prompts)\n",
        "            per_template_features.append(features.cpu())\n",
        "        per_template_features = torch.stack(per_template_features)\n",
        "        averaged_features = per_template_features.mean(dim=0)\n",
        "        averaged_features = averaged_features / averaged_features.norm(dim=-1, keepdim=True)\n",
        "        return {\"per_template\": per_template_features, \"averaged\": averaged_features}\n",
        "\n",
        "print(\"\ud83d\udce6 CLIPTextEncoder defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca Metric Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entropy and Other Metrics\n",
        "def compute_entropy(probs, dim=1, eps=1e-10):\n",
        "    \"\"\"Lower entropy = higher confidence = better template.\"\"\"\n",
        "    log_probs = torch.log(probs + eps)\n",
        "    return -(probs * log_probs).sum(dim=dim)\n",
        "\n",
        "def compute_max_prob(probs, dim=1):\n",
        "    \"\"\"Higher max prob = higher confidence = better template.\"\"\"\n",
        "    return probs.max(dim=dim)[0]\n",
        "\n",
        "def compute_margin(probs, dim=1):\n",
        "    \"\"\"Higher margin = more decisive = better template.\"\"\"\n",
        "    sorted_probs = probs.sort(dim=dim, descending=True)[0]\n",
        "    return sorted_probs.select(dim, 0) - sorted_probs.select(dim, 1)\n",
        "\n",
        "METRICS = {\n",
        "    \"entropy\": {\"fn\": compute_entropy, \"lower_is_better\": True},\n",
        "    \"max_prob\": {\"fn\": compute_max_prob, \"lower_is_better\": False},\n",
        "    \"margin\": {\"fn\": compute_margin, \"lower_is_better\": False},\n",
        "}\n",
        "\n",
        "print(\"\ud83d\udcca Metrics defined: entropy, max_prob, margin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83c\udfaf YOUR CUSTOM METRIC - Edit this to beat entropy!\n",
        "def compute_custom_metric(probs, dim=1, eps=1e-10):\n",
        "    \"\"\"\n",
        "    \ud83c\udfaf YOUR CUSTOM METRIC!\n",
        "    \n",
        "    Implement your own metric here to beat entropy!\n",
        "    \"\"\"\n",
        "    # Example: Weighted combination of entropy and margin\n",
        "    entropy = compute_entropy(probs, dim=dim, eps=eps)\n",
        "    margin = compute_margin(probs, dim=dim)\n",
        "    return entropy - 0.3 * margin\n",
        "\n",
        "METRICS[\"custom\"] = {\"fn\": compute_custom_metric, \"lower_is_better\": True}\n",
        "print(\"\u2705 Custom metric registered!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd04 Compute Text Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load or compute text features\n",
        "print(\"\ud83e\uddee Computing text features...\")\n",
        "text_encoder = CLIPTextEncoder()\n",
        "text_features = text_encoder.compute_all_text_features(current_classes)\n",
        "\n",
        "print(f\"\\n\ud83d\udcca Text features ready:\")\n",
        "print(f\"   Per-template: {text_features['per_template'].shape}\")\n",
        "print(f\"   Averaged: {text_features['averaged'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcc8 Template Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Template Ranker\n",
        "class TemplateRanker:\n",
        "    def __init__(self, text_features, class_names, templates=IMAGENET_TEMPLATES, temperature=0.01):\n",
        "        self.text_features = text_features\n",
        "        self.class_names = class_names\n",
        "        self.templates = templates\n",
        "        self.temperature = temperature\n",
        "        self.num_templates = len(templates)\n",
        "        self.num_classes = len(class_names)\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "        self.metric_accumulator = defaultdict(lambda: defaultdict(lambda: {\"sum\": 0.0, \"count\": 0}))\n",
        "        self.total_pixels = 0\n",
        "        \n",
        "    def compute_segmentation_probs(self, image_features):\n",
        "        B, dim, H, W = image_features.shape\n",
        "        per_template = self.text_features[\"per_template\"]\n",
        "        T, C, D = per_template.shape\n",
        "        reshaped = per_template.reshape(-1, D)\n",
        "        output = F.conv2d(image_features, reshaped[:, :, None, None])\n",
        "        output = output.reshape(B, T, C, H, W)\n",
        "        probs = F.softmax(output / self.temperature, dim=2)\n",
        "        return probs.permute(1, 0, 2, 3, 4)\n",
        "    \n",
        "    def update_metrics(self, image_features, metric_name=\"entropy\"):\n",
        "        B, _, H, W = image_features.shape\n",
        "        probs = self.compute_segmentation_probs(image_features)\n",
        "        metric_fn = METRICS[metric_name][\"fn\"]\n",
        "        \n",
        "        for t_idx in range(self.num_templates):\n",
        "            template_probs = probs[t_idx]\n",
        "            metric_values = metric_fn(template_probs, dim=1)\n",
        "            predictions = template_probs.argmax(dim=1)\n",
        "            \n",
        "            for c_idx in range(self.num_classes):\n",
        "                mask = predictions == c_idx\n",
        "                if mask.any():\n",
        "                    class_metric = metric_values[mask]\n",
        "                    self.metric_accumulator[t_idx][c_idx][\"sum\"] += class_metric.sum().item()\n",
        "                    self.metric_accumulator[t_idx][c_idx][\"count\"] += mask.sum().item()\n",
        "        \n",
        "        self.total_pixels += B * H * W\n",
        "        \n",
        "    def compute_rankings(self, metric_name=\"entropy\"):\n",
        "        lower_is_better = METRICS[metric_name][\"lower_is_better\"]\n",
        "        rankings = {\"classes\": {}}\n",
        "        \n",
        "        for c_idx, class_name in enumerate(self.class_names):\n",
        "            template_scores = []\n",
        "            for t_idx in range(self.num_templates):\n",
        "                data = self.metric_accumulator[t_idx][c_idx]\n",
        "                if data[\"count\"] > 0:\n",
        "                    avg_metric = data[\"sum\"] / data[\"count\"]\n",
        "                    pixel_pct = (data[\"count\"] / self.total_pixels) * 100\n",
        "                else:\n",
        "                    avg_metric = float('inf') if lower_is_better else float('-inf')\n",
        "                    pixel_pct = 0.0\n",
        "                template_scores.append({\"template_id\": t_idx, metric_name: avg_metric, \"pixel_percentage\": pixel_pct})\n",
        "            \n",
        "            sorted_scores = sorted(template_scores, key=lambda x: x[metric_name], reverse=not lower_is_better)\n",
        "            for rank, score in enumerate(sorted_scores, 1):\n",
        "                score[\"rank\"] = rank\n",
        "            rankings[\"classes\"][class_name] = {f\"{metric_name}_ranking\": sorted_scores}\n",
        "        \n",
        "        return rankings\n",
        "\n",
        "print(\"\ud83d\udce6 TemplateRanker defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf Demo with Synthetic Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic features for demo\n",
        "def generate_synthetic_features(num_images=50, height=28, width=28, dim=512):\n",
        "    features = []\n",
        "    for _ in tqdm(range(num_images), desc=\"Generating features\"):\n",
        "        feat = torch.randn(1, dim, height, width)\n",
        "        feat = feat / feat.norm(dim=1, keepdim=True)\n",
        "        features.append(feat)\n",
        "    return features\n",
        "\n",
        "synthetic_features = generate_synthetic_features(num_images=50)\n",
        "print(f\"\u2705 Generated {len(synthetic_features)} synthetic feature maps\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute Rankings\n",
        "METRIC_NAME = \"entropy\"  # Try: entropy, max_prob, margin, custom\n",
        "\n",
        "print(f\"\ud83d\udcca Computing rankings using: {METRIC_NAME}\")\n",
        "\n",
        "ranker = TemplateRanker(text_features=text_features, class_names=current_classes)\n",
        "\n",
        "for feat in tqdm(synthetic_features, desc=\"Processing\"):\n",
        "    ranker.update_metrics(feat, metric_name=METRIC_NAME)\n",
        "\n",
        "rankings = ranker.compute_rankings(metric_name=METRIC_NAME)\n",
        "print(f\"\\n\u2705 Rankings computed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display Rankings\n",
        "print(f\"\\n\ud83c\udfc6 Top-3 Templates per Class (by {METRIC_NAME})\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "ranking_field = f\"{METRIC_NAME}_ranking\"\n",
        "for class_name, class_data in list(rankings[\"classes\"].items())[:5]:\n",
        "    top_templates = class_data[ranking_field][:3]\n",
        "    print(f\"\\n\ud83d\udccc {class_name}:\")\n",
        "    for t in top_templates:\n",
        "        template_str = IMAGENET_TEMPLATES[t['template_id']].format(class_name)\n",
        "        print(f\"   [{t['rank']:2d}] T{t['template_id']:2d} | {METRIC_NAME}={t[METRIC_NAME]:.4f} | \\\"{template_str}\\\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Rankings\n",
        "def visualize_rankings(rankings, metric_name, num_classes=8):\n",
        "    ranking_field = f\"{metric_name}_ranking\"\n",
        "    class_names = list(rankings[\"classes\"].keys())[:num_classes]\n",
        "    \n",
        "    rank_matrix = np.zeros((len(class_names), 80))\n",
        "    for i, cn in enumerate(class_names):\n",
        "        for t_data in rankings[\"classes\"][cn][ranking_field]:\n",
        "            rank_matrix[i, t_data[\"template_id\"]] = t_data[\"rank\"]\n",
        "    \n",
        "    plt.figure(figsize=(16, 6))\n",
        "    im = plt.imshow(rank_matrix, cmap=\"RdYlGn_r\", aspect=\"auto\")\n",
        "    plt.yticks(range(len(class_names)), class_names)\n",
        "    plt.xlabel(\"Template ID\")\n",
        "    plt.ylabel(\"Class\")\n",
        "    plt.title(f\"Template Rankings by {metric_name.capitalize()}\")\n",
        "    plt.colorbar(im, label=\"Rank\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_rankings(rankings, METRIC_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfc1 Load Paper's Rankings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Paper Rankings\n",
        "def load_paper_rankings(dataset, model=\"naclip\"):\n",
        "    if IN_COLAB:\n",
        "        path = f\"/content/FLOSS/rankings/{model}/template_rankings_{model}_{dataset}.json\"\n",
        "    else:\n",
        "        path = f\"rankings/{model}/template_rankings_{model}_{dataset}.json\"\n",
        "    \n",
        "    try:\n",
        "        with open(path, \"r\") as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\u26a0\ufe0f Rankings not found at {path}\")\n",
        "        return None\n",
        "\n",
        "paper_rankings = load_paper_rankings(DATASET, MODEL_TYPE)\n",
        "\n",
        "if paper_rankings:\n",
        "    print(\"\ud83d\udcc4 Paper's Entropy Rankings (Top 3):\")\n",
        "    for cn in list(paper_rankings[\"classes\"].keys())[:3]:\n",
        "        ranking = paper_rankings[\"classes\"][cn].get(\"entropy_ranking\", [])[:3]\n",
        "        print(f\"\\n   {cn}: {[t['template_id'] for t in ranking]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udf89 Summary\n",
        "\n",
        "You've learned how to:\n",
        "- Compute template rankings using entropy\n",
        "- Experiment with custom metrics\n",
        "- Visualize and compare results\n",
        "\n",
        "**Challenge:** Can you find a better metric than entropy? Edit `compute_custom_metric()`!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}